# =============================================================================
# Script: app.py
# =============================================================================
# Purpose
#   Expose a REST API that accepts JD, CV, and Skill Tree (plus optional
#   question guidelines) and returns the full agenda JSON generated by
#   AgendaGenerationAgent. Intended for synchronous, single-request use
#   with a configurable timeout.
#
# Behavior
#   - Defines a FastAPI app with a lifespan context:
#       * Startup: prepare lightweight shared resources (if any).
#       * Shutdown: close Mongo connections and clear shared objects.
#   - Provides endpoints:
#       * GET /health: liveness check.
#       * POST /agenda_create: runs the agenda pipeline and returns JSON.
#   - Builds an InputSchema from the request payload and forwards a
#     thread_id through config so downstream agents run accordingly and tag logs correctly.
#   - Normalizes Pydantic outputs to plain dicts before responding.
#   - Logs high-level events and converts internal failures to HTTP errors:
#       * 500 on unhandled exceptions.
#   - Leaves pipeline details (LLM retries, per-node logging) to the
#     underlying agents.
# =============================================================================


import asyncio
import logging
import os
from contextlib import asynccontextmanager
from typing import Any, Dict, Optional

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field

from src.agent.AgendaGenerationAgent import run_agenda_with_logging
from src.mongo_tools import close_all_mongo_connections
from src.schema.input_schema import (
    CandidateProfileSchema,
    InputSchema,
    JobDescriptionSchema,
    SkillTreeSchema,
)

APP_NAME = "agenda_api"
logger = logging.getLogger(APP_NAME)
if not logger.handlers:
    logging.basicConfig(
        level=getattr(
            logging, os.getenv("AGENDA_API_LOG_LEVEL", "INFO").upper(), logging.INFO
        ),
        format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
    )

# Simple in-memory job store. Swap with Redis/Celery/RQ in prod.
# JOBS[job_id] = {"status": "queued|running|done|error", "result": dict|None, "error": str|None, "thread_id": str}
JOBS: Dict[str, Dict[str, Any]] = {}


@asynccontextmanager
async def lifespan(app: FastAPI):
    # ---- STARTUP ----
    try:
        pass
    except Exception:
        logger.exception("Startup initialization failed")
        raise

    yield

    # ---- SHUTDOWN ----
    try:
        close_all_mongo_connections()
    except Exception:
        logger.warning("close_all_mongo_connections raised but continuing shutdown")
    JOBS.clear()


app = FastAPI(title="Agenda API", version="1.1.0", lifespan=lifespan)


# ----------------------------
# Models
# ----------------------------
class AgendaRequest(BaseModel):
    job_description: JobDescriptionSchema = Field(..., description="Job description")
    candidate_profile: CandidateProfileSchema = Field(
        ..., description="Candidate CV/profile"
    )
    skill_tree: SkillTreeSchema = Field(..., description="Skill tree")
    question_guidelines: Optional[Dict[str, Any]] = Field(
        default=None, description="Optional question guidelines dict"
    )
    config: Optional[Dict[str, Any]] = Field(
        default=None, description="Optional graph config to override defaults"
    )
    thread_id: Optional[str] = Field(
        default=None, description="Optional thread id for logging/tracing"
    )


class AgendaCreateResponse(BaseModel):
    job_id: str
    status: str
    thread_id: str


class AgendaStatusResponse(BaseModel):
    job_id: str
    status: str
    error: Optional[str] = None
    thread_id: Optional[str] = None


class AgendaResultResponse(BaseModel):
    job_id: str
    status: str
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    thread_id: Optional[str] = None


# ----------------------------
# Helpers
# ----------------------------
def _normalize_output(otpt: Dict[str, Any]) -> Dict[str, Any]:
    """Convert Pydantic models / dicts into plain JSON-able dicts."""
    norm: Dict[str, Any] = {}
    for k, v in otpt.items():
        key = str(k)
        try:
            if hasattr(v, "model_dump"):
                norm[key] = v.model_dump()
            elif hasattr(v, "dict"):
                norm[key] = v.dict()
            else:
                norm[key] = v
        except Exception:
            norm[key] = v
    return norm


async def _run_job(job_id: str, req: AgendaRequest):
    """Background task: executes the agenda pipeline and caches the result."""
    try:
        JOBS[job_id]["status"] = "running"
        thread_id = JOBS[job_id]["thread_id"]

        # Build InputSchema
        inp = InputSchema(
            job_description=req.job_description,
            skill_tree=req.skill_tree,
            candidate_profile=req.candidate_profile,
            # The pipeline accepts dict or model; keep structure the same as earlier usage
            question_guidelines=req.question_guidelines or {"question_guidelines": []},
        )

        # Merge user-provided config, ensure thread_id flows to the graph
        merged_config = (req.config or {}).copy()
        merged_config.setdefault("configurable", {})
        merged_config["configurable"].setdefault("thread_id", thread_id)

        out = await run_agenda_with_logging(inp, merged_config)
        JOBS[job_id]["status"] = "done"
        JOBS[job_id]["result"] = _normalize_output(out)
    except Exception as e:
        JOBS[job_id]["status"] = "error"
        JOBS[job_id]["error"] = str(e)
        logger.exception("Job %s failed", job_id)


# ----------------------------
# Routes
# ----------------------------
@app.get("/health")
async def health():
    return {"ok": True}


@app.post("/agenda_create", response_model=AgendaCreateResponse, status_code=202)
async def agenda_create(req: AgendaRequest):
    """
    Enqueue a long-running agenda generation task.
    Returns immediately with a job_id and thread_id.
    """
    # Use provided thread_id or derive from job_id for consistent per-thread logs
    base_id = req.thread_id or f"thread_{os.urandom(4).hex()}"
    job_id = base_id  # keep them identical so logs and API ids match
    if job_id in JOBS:
        # avoid accidental collision; extremely unlikely unless reused by caller
        job_id = f"{base_id}_{os.urandom(2).hex()}"

    JOBS[job_id] = {
        "status": "queued",
        "result": None,
        "error": None,
        "thread_id": job_id,
    }
    # Run-and-forget task
    asyncio.create_task(_run_job(job_id, req))

    return AgendaCreateResponse(job_id=job_id, status="queued", thread_id=job_id)


@app.get("/agenda_status/{job_id}", response_model=AgendaStatusResponse)
async def agenda_status(job_id: str):
    job = JOBS.get(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="job_id not found")
    return AgendaStatusResponse(
        job_id=job_id,
        status=job["status"],
        error=job.get("error"),
        thread_id=job.get("thread_id"),
    )


@app.get("/agenda_result/{job_id}", response_model=AgendaResultResponse)
async def agenda_result(job_id: str):
    job = JOBS.get(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="job_id not found")
    if job["status"] != "done":
        # Return status until finished; client can poll
        return AgendaResultResponse(
            job_id=job_id,
            status=job["status"],
            error=job.get("error"),
            thread_id=job.get("thread_id"),
            result=None,
        )
    return AgendaResultResponse(
        job_id=job_id,
        status="done",
        result=job["result"],
        error=None,
        thread_id=job.get("thread_id"),
    )
