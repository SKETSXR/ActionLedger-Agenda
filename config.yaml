configurable:
  # model: moonshotai/kimi-k2-instruct
  # model: llama3.2
  # model_provider: ollama
  # model: qwen3
  # model_provider: ollama
  # model_provider: groq
  # model: gemini-2.5-pro
  # model_provider: google_genai
  # model: mistralai/mixtral-8x7b-instruct-v0.1
  # model: openai/gpt-oss-120b
  # model: openai/gpt-oss-20b
  # model_provider: nvidia
  # temperature: 0
  # verbosity: low
  # reasoning_effort: minimal

  # Open AI models
  model_provider_jd: openai
  model_jd: gpt-4o
  # reasoning_effort_jd: minimal
  temperature_jd: 0

  model_provider_cv: openai
  model_cv: gpt-4o
  # reasoning_effort_cv: minimal
  temperature_cv: 0

  model_provider_sg: openai
  model_sg: gpt-4o
  # reasoning_effort_sg: minimal
  temperature_sg: 0
  model_provider_tg: openai
  model_tg: gpt-4o
  # reasoning_effort_tg: minimal
  temperature_tg: 0

  model_provider_dts: openai
  model_dts: gpt-4o
  # reasoning_effort_dts: minimal
  temperature_dts: 0

  model_provider_n: openai
  model_n: gpt-4o
  # reasoning_effort_n: minimal
  temperature_n: 0

  model_provider_qa: openai
  model_qa: gpt-4o
  # reasoning_effort_qa: minimal
  temperature_qa: 0

  thread_id: thread_11
  
  
  # # Open AI models
  # model_provider_jd: google_genai
  # model_jd: gemini-2.5-flash
  # # reasoning_effort_jd: minimal
  # temperature_jd: 0

  # model_provider_cv: google_genai
  # model_cv: gemini-2.5-flash
  # # reasoning_effort_cv: minimal
  # temperature_cv: 0

  # model_provider_sg: google_genai
  # model_sg: gemini-2.5-flash
  # # reasoning_effort_sg: minimal
  # temperature_sg: 0
  # model_provider_tg: google_genai
  # model_tg: gemini-2.5-flash
  # # reasoning_effort_tg: minimal
  # temperature_tg: 0

  # model_provider_dts: google_genai
  # model_dts: gemini-2.5-flash
  # # reasoning_effort_dts: minimal
  # temperature_dts: 0

  # model_provider_n: google_genai
  # model_n: gemini-2.5-flash
  # # reasoning_effort_n: minimal
  # temperature_n: 0

  # model_provider_qa: google_genai
  # model_qa: gemini-2.5-flash
  # # reasoning_effort_qa: minimal
  # temperature_qa: 0

  # thread_id: thread_9
  
  
  # # Open AI models
  # model_provider_jd: ollama
  # model_jd: llama3.2
  # # reasoning_effort_jd: minimal
  # temperature_jd: 0

  # model_provider_cv: ollama
  # model_cv: llama3.2
  # # reasoning_effort_cv: minimal
  # temperature_cv: 0

  # model_provider_sg: ollama
  # model_sg: llama3.2
  # # reasoning_effort_sg: minimal
  # temperature_sg: 0
  # model_provider_tg: ollama
  # model_tg: llama3.2
  # # reasoning_effort_tg: minimal
  # temperature_tg: 0

  # model_provider_dts: ollama
  # model_dts: llama3.2
  # # reasoning_effort_dts: minimal
  # temperature_dts: 0

  # model_provider_n: ollama
  # model_n: llama3.2
  # # reasoning_effort_n: minimal
  # temperature_n: 0

  # model_provider_qa: ollama
  # model_qa: llama3.2
  # # reasoning_effort_qa: minimal
  # temperature_qa: 0

  # thread_id: thread_9
  